{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#            Implementation of Image Web Scraping using Selenium Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1. Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2. Install Chrome Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\oelyd\\.wdm\\drivers\\chromedriver\\win32\\88.0.4324.96\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "#Install Driver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3. Specify Search url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Search URL\n",
    "search_url = \"https://www.google.com/search?q={q}&tbm=isch&tbs=sur%3Afc&hl=en&ved=0CAIQpwVqFwoTCKCa1c6s4-oCFQAAAAAdAAAAABAC&biw=1251&bih=568\"\n",
    "driver.get(search_url.format(q='go sport'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - I've used this specific URL so you don't get in trouble for using licensed or images with copyrights. Otherwise you can use https://google.com also as search URL .\n",
    " - Then we're searching for Car in our Search URL.\n",
    "\n",
    "### Paste the link into to driver.get(“ Your Link Here ”) function and run the cell. This will open a new browser window for that link. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4. Scroll to the end of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scroll to the end of the page\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)#sleep_between_interactions  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above line of code would help us to reach the end of the page . And then we're giving sleep time of 5 seconds so we don't run in problem , where we're trying to read elements from page , which is not yet loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5. Locate the images to be scraped from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate the images to be scraped from the current page\n",
    "imgResults = driver.find_elements_by_xpath(\"//img[contains(@class,'Q4LuWd')]\")\n",
    "totalResults=len(imgResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll fetch all the image links present on that particular page. We will create a “list” to store those links.\n",
    "So, to do that go to the browser window, right-click on the page, and select ‘inspect element’ or enable the dev tools using Ctrl+Shift+I .\n",
    "Now identify any attribute such as class , id etc. Which is common across all these images.\n",
    "\n",
    "In our case class =\"'Q4LuWd\" is common across all these images. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step6. Extract corresponding link of each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on each Image to extract its corresponding link to download\n",
    "\n",
    "img_urls = set()\n",
    "for i in  range(0,len(imgResults)):\n",
    "    img=imgResults[i]\n",
    "    try:\n",
    "        img.click()\n",
    "        time.sleep(2)\n",
    "        actual_images = driver.find_elements_by_css_selector('img.n3VNCb')\n",
    "        for actual_image in actual_images:\n",
    "            if actual_image.get_attribute('src') and 'https' in actual_image.get_attribute('src'):\n",
    "                img_urls.add(actual_image.get_attribute('src'))\n",
    "    except ElementClickInterceptedException or ElementNotInteractableException as err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So in the above snippet of code , we're performing following tasks\n",
    "   - Iterate through each thumbnail and then on click it .\n",
    "   - Make our browser sleep for 2 seconds (:P) .\n",
    "   - Find the unique html tag corresponding to that image to locate it on page\n",
    "   - We still get more than one result for particular image .  But all we're interested in the link for that image to download.\n",
    "\n",
    "So we iterate through each result for that image and extract 'src' attribute of it and then see whether \"https\" is present in the 'src'  or not. Since typically web link starts with 'https'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step7. Download & save each image in Destination directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('C:/Qurantine/Blog/WebScrapping/Dataset1')\n",
    "#os.chdir('C:/Users/oelyd/Desktop/image_processing_side_projects/Web-Scraping-using-Selenium-Python-master/res_tarmak')\n",
    "os.chdir('C:/Users/oelyd/Desktop/image_processing_side_projects/scraping_gosport')\n",
    "baseDir=os.getcwd()\n",
    "\n",
    "for i, url in enumerate(img_urls):\n",
    "    file_name = f\"{i:150}.jpg\"    \n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - COULD NOT DOWNLOAD {url} - {e}\")\n",
    "\n",
    "    try:\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "        \n",
    "        file_path = os.path.join(baseDir, file_name)\n",
    "        \n",
    "        with open(file_path, 'wb') as f:\n",
    "            image.save(f, \"JPEG\", quality=85)\n",
    "        print(f\"SAVED - {url} - AT: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - COULD NOT SAVE {url} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
